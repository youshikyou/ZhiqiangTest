{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05da7a9f-ef42-4d03-9fee-1beb2cc68d59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T17:47:59.467524Z",
     "iopub.status.busy": "2022-01-23T17:47:59.467206Z",
     "iopub.status.idle": "2022-01-23T17:48:28.440337Z",
     "shell.execute_reply": "2022-01-23T17:48:28.438353Z",
     "shell.execute_reply.started": "2022-01-23T17:47:59.467485Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4063e2fadc4157ba6824efa93ea0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>2</td><td>application_1642957983790_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-34-59.eu-north-1.compute.internal:20888/proxy/application_1642957983790_0003/\" class=\"emr-proxy-link\" emr-resource=\"j-3QMBP6ZIUMQDR\n",
       "\" application-id=\"application_1642957983790_0003\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-34-59.eu-north-1.compute.internal:8042/node/containerlogs/container_1642957983790_0003_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#spark is spark.session, sc is spark context\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70fedcd8-ecd5-440e-a07e-a8c7c719b932",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T18:03:11.709798Z",
     "iopub.status.busy": "2022-01-23T18:03:11.709575Z",
     "iopub.status.idle": "2022-01-23T18:03:21.051527Z",
     "shell.execute_reply": "2022-01-23T18:03:21.050932Z",
     "shell.execute_reply.started": "2022-01-23T18:03:11.709774Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1e4e4226d54d619712f8c353ee1589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 =spark.read.option(\"header\",\"true\").csv(\"s3://zhiqiangcasestudy/bedandBLD_master_list_20200203.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99019eda-66ce-47e0-9f5a-2d42c2f4b74f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T18:06:49.956078Z",
     "iopub.status.busy": "2022-01-23T18:06:49.955858Z",
     "iopub.status.idle": "2022-01-23T18:06:57.303069Z",
     "shell.execute_reply": "2022-01-23T18:06:57.302267Z",
     "shell.execute_reply.started": "2022-01-23T18:06:49.956055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda936c8c5a8433e94849fa2f4b9c84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|hotel_id|         hotel_name|\n",
      "+--------+-------------------+\n",
      "|      a1|    The Great Hotel|\n",
      "|      b2|     Marigold Hotel|\n",
      "|      c3|           Dormitel|\n",
      "|      e4|           HotelBnB|\n",
      "|      f5|          Sky Stays|\n",
      "|      g6|Mini Capsule Hotels|\n",
      "|      h7|  New Trivago Hotel|\n",
      "|      i8|      The Lakehouse|\n",
      "+--------+-------------------+"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70993dbd-03f0-4d5b-abf5-4fad1454d618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T18:07:57.540259Z",
     "iopub.status.busy": "2022-01-23T18:07:57.540029Z",
     "iopub.status.idle": "2022-01-23T18:07:58.330935Z",
     "shell.execute_reply": "2022-01-23T18:07:58.330012Z",
     "shell.execute_reply.started": "2022-01-23T18:07:57.540235Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf1805a203340e689091c25e2ba7fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = spark.read.option(\"header\",\"true\").csv(\"s3://zhiqiangcasestudy/lookandbook_hotel_list_20200203.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "333a9b19-312a-40a2-89d3-a28349524604",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T18:08:00.392743Z",
     "iopub.status.busy": "2022-01-23T18:08:00.392524Z",
     "iopub.status.idle": "2022-01-23T18:08:00.667591Z",
     "shell.execute_reply": "2022-01-23T18:08:00.666928Z",
     "shell.execute_reply.started": "2022-01-23T18:08:00.392721Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ca97aad80441308cf5708ad81e8d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|hotel_id|         hotel_name|\n",
      "+--------+-------------------+\n",
      "|       1|    The Great Hotel|\n",
      "|       2|     Marigold Hotel|\n",
      "|       3|   The Manila Hotel|\n",
      "|       4|           Dormitel|\n",
      "|       5|           HotelBnB|\n",
      "|       6|  Antarctica Igloos|\n",
      "|       7|          Sky Stays|\n",
      "|       8|Mini Capsule Hotels|\n",
      "|       9|  New Trivago Hotel|\n",
      "|      10|      The Lakehouse|\n",
      "+--------+-------------------+"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6801acb0-fb74-49c8-8289-901647b4efcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T18:09:01.716456Z",
     "iopub.status.busy": "2022-01-23T18:09:01.716219Z",
     "iopub.status.idle": "2022-01-23T18:09:01.783346Z",
     "shell.execute_reply": "2022-01-23T18:09:01.782776Z",
     "shell.execute_reply.started": "2022-01-23T18:09:01.716432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9314ed491402490695611c352d9b691c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_concat = df1.union(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6effe51-b073-481f-bfd7-c4118bb94f11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-23T18:09:09.599342Z",
     "iopub.status.busy": "2022-01-23T18:09:09.599119Z",
     "iopub.status.idle": "2022-01-23T18:09:16.917409Z",
     "shell.execute_reply": "2022-01-23T18:09:16.916804Z",
     "shell.execute_reply.started": "2022-01-23T18:09:09.599319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e87bb5637ae46d9a83ad90c033e2a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|hotel_id|         hotel_name|\n",
      "+--------+-------------------+\n",
      "|      a1|    The Great Hotel|\n",
      "|      b2|     Marigold Hotel|\n",
      "|      c3|           Dormitel|\n",
      "|      e4|           HotelBnB|\n",
      "|      f5|          Sky Stays|\n",
      "|      g6|Mini Capsule Hotels|\n",
      "|      h7|  New Trivago Hotel|\n",
      "|      i8|      The Lakehouse|\n",
      "|       1|    The Great Hotel|\n",
      "|       2|     Marigold Hotel|\n",
      "|       3|   The Manila Hotel|\n",
      "|       4|           Dormitel|\n",
      "|       5|           HotelBnB|\n",
      "|       6|  Antarctica Igloos|\n",
      "|       7|          Sky Stays|\n",
      "|       8|Mini Capsule Hotels|\n",
      "|       9|  New Trivago Hotel|\n",
      "|      10|      The Lakehouse|\n",
      "+--------+-------------------+"
     ]
    }
   ],
   "source": [
    "df_concat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca5cd9e-816c-451f-9997-6d4e0c4835af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhiqiangyang/Downloads/data_integration\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "mypath= os.getcwd()\n",
    "print(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8cc3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(mypath):\n",
    "    f.extend(filenames)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73bfc86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4ff1c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['case_study.md', '.DS_Store', 'README.md', 'trivagocasestudy.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd179fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The case_study.md's format name is invalid\n",
      "The .DS_Store's format name is invalid\n",
      "The README.md's format name is invalid\n",
      "The trivagocasestudy.ipynb's format name is invalid\n"
     ]
    }
   ],
   "source": [
    "ALLOWED_EXTENSTIONS = {\".csv\"}\n",
    "for i in f:\n",
    "    extension = os.path.splitext(i)[1]\n",
    "    if extension not in ALLOWED_EXTENSTIONS:\n",
    "        print(\"The {}'s format name is invalid\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "ALLOWED_EXTENSTIONS = {\".csv\"}\n",
    "\n",
    "def fileNameCheck(mypath):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    filenames = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "    for filename in filenames:\n",
    "        extension = os.path.splitext(filename)[1]\n",
    "        if extension not in ALLOWED_EXTENSTIONS:\n",
    "            print(\"The {}'s format name is invalid\".format(i))\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "\n",
    "Never open text files without specifying an encoding (this is generally true).\n",
    "Always open CSV files with newline='' (this applies to the Python csv module)\n",
    "\n",
    "with open('output.csv', 'r', encoding='UTF-8', newline='') as csvarchive:\n",
    "    entrada = csv.reader(csvarchive)\n",
    "\n",
    "\n",
    "#find special character\n",
    "#try:\n",
    "#field.encode(encoding='utf-8').decode('ascii')\n",
    "#except UnicodeEncodeError:\n",
    "# print(\"not english\")\n",
    "\n",
    "#if not field.isascii():\n",
    "# print(\"find special \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "c6ab33a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line.9 has the extra comma.\n",
      "/Users/zhiqiangyang/Downloads/data_integration/input_files/bedandBLD_master_list_20200203.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import csv\n",
    "\n",
    "#mypath = os.getcwd()+\"/input_files/lookandbook_hotel_list_20200203.csv\"\n",
    "mypath = os.getcwd()+\"/input_files/bedandBLD_master_list_20200203.csv\"\n",
    "dirpath = os.getcwd()\n",
    "\n",
    "\"\"\"\n",
    "In this code, I assume the csv file uses delimiter ',' and every field has its quote.\n",
    "Because if without quote, the extra comma \n",
    "for example \n",
    "10,The, Lakehouse\n",
    "Above row will not be considered as extra comma\n",
    "So when one row is like\n",
    "\"10\",,,\"The Lakehouse\", then this is extra comma,\n",
    "but \"10\",\"The,Lakehouse\" is not considered as extra comma.\n",
    "\"10\",\"The\", \"Lakehouse\" is not considered as extra comma\n",
    "\n",
    "\"\"\"\n",
    "ALLOWED_EXTENSTIONS = {\".csv\"}\n",
    "ALLOWED_DELIMITER =[',']\n",
    "\n",
    "\n",
    "# define Python user-defined exceptions\n",
    "class Error(Exception):\n",
    "    \"\"\"Base class for other exceptions\"\"\"\n",
    "    pass\n",
    "\n",
    "class FileNameFormatError(Error):\n",
    "    \"\"\"Raised when the file name format is not allowed\"\"\"\n",
    "    pass\n",
    "\n",
    "class UnicodeEncodeError(Error):\n",
    "  \"\"\"Raised when there is special character in field\"\"\"\n",
    "  pass\n",
    "\n",
    "def file_name_format_Check(dirpath):\n",
    "    \"\"\"The file name format check\n",
    "\n",
    "    Args:\n",
    "      mypath: a directory path\n",
    "\n",
    "    Returns:\n",
    "      None\n",
    "\n",
    "    Raises:\n",
    "      FileNameFormatError: If the path's file name format is not valid\n",
    "    \"\"\"\n",
    "\n",
    "    filenames = [f for f in listdir(dirpath) if isfile(join(dirpath, f))]\n",
    "    for filename in filenames:\n",
    "        extension = os.path.splitext(filename)[1]\n",
    "        try:\n",
    "            if extension not in ALLOWED_EXTENSTIONS:\n",
    "                raise FileNameFormatError\n",
    "        except FileNameFormatError :\n",
    "            print(\"{} is not a valid file name format\".format(filename))\n",
    "\n",
    "def file_empty_check(mypath):\n",
    "  is_empty = os.path.exists(mypath) and os.stat(mypath).st_size == 0\n",
    "  if is_empty:\n",
    "      print('File is empty')\n",
    "  else:\n",
    "      print('File is not empty')\n",
    "\n",
    "\n",
    "def file_header_check(mypath):\n",
    "  with open(mypath, 'r') as csvfile:\n",
    "    sampledata =csvfile.read(1024)\n",
    "    has_header = csv.Sniffer().has_header(sampledata)\n",
    "    if has_header:\n",
    "      print(\"File has header\")\n",
    "    else:\n",
    "      print(\"File has not header\")\n",
    "\n",
    "def file_is_wrong_delimiter(mypath):\n",
    "    with open(mypath, 'r',encoding='UTF-8') as csvfile:\n",
    "      try:\n",
    "        dialect = csv.Sniffer().sniff(csvfile.readline(), ALLOWED_DELIMITER)\n",
    "        is_wrong_delimiter = False\n",
    "        print(\"Delimiter is \\\"{}\\\"\".format(dialect.delimiter))\n",
    "      except:\n",
    "        is_wrong_delimiter = True\n",
    "        print(\"Wrong Delimiter\")\n",
    "    return is_wrong_delimiter\n",
    "\n",
    "\n",
    "def file_has_extra_comma(mypath):\n",
    "  with open(mypath, 'r') as csvfile:\n",
    "    csvreader = csv.reader(csvfile, delimiter = \",\",quotechar='\"')\n",
    "    for linenum,fieldlist in enumerate(csvreader):\n",
    "      if '' in set(fieldlist):\n",
    "        print(\"Line.{} has the extra comma.\".format(linenum+1))\n",
    "        return True\n",
    "  return False\n",
    "\n",
    "def field_has_specialchar(mypath):\n",
    "\n",
    "    with open(mypath, 'r', encoding='UTF-8', newline='') as csvfile:\n",
    "    #with open(mypath, 'r') as csvfile:\n",
    "      csvreader = csv.reader(csvfile, delimiter = \",\",quotechar='\"')\n",
    "      for fieldlist in csvreader:\n",
    "        for field in fieldlist:\n",
    "           if re.compile('[^ 0-9a-zA-Z_-]+').search(field):\n",
    "             print(\"{} contains special character.\".format(field))\n",
    "             return True\n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "check file format name, check file empty, check delimiter,check header\n",
    "\"\"\"\n",
    "#file_delimiter_check(mypath)\n",
    "#file_header_check(mypath)\n",
    "file_has_extra_comma(mypath)\n",
    "#field_has_specialchar(mypath)\n",
    "\n",
    "print(mypath)\n",
    "#file_is_wrong_delimiter(mypath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75d27f",
   "metadata": {},
   "source": [
    "### Task1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae7a146",
   "metadata": {},
   "source": [
    "Provide the table DDL for trivago.advertiser_hotels\n",
    "1. Create a table first\n",
    "```\n",
    "            CREATE TABLE IF NOT EXISTS advertiser_hotels_ddl (\n",
    "            hotel_id string,\n",
    "            hotel_name string,)\n",
    "            COMMENT 'DDL table'\n",
    "            ROW FORMAT DELIMITED\n",
    "            FIELDS TERMINATED BY ',';\n",
    "```\n",
    "2. Load data into the table\n",
    "```\n",
    "    LOAD DATA INPATH '/input_files/bedandBLD_master_list_20200203.csv' INTO TABLE advertiser_hotels_ddl\n",
    "    LOAD DATA INPATH '/input_files/lookandbook_hotel_list_20200203.csv' INTO TABLE advertiser_hotels_ddl\n",
    "```\n",
    "Provide a list of commands needed or a step-by-step guide to load the data into HDFS\n",
    "1. Starting HDFS\n",
    "```\n",
    "    hadoop namenode -format\n",
    "```\n",
    "2. Create an input directory\n",
    "```\n",
    "    hadoop fs -mkdir /user/solution/task1/\n",
    "```\n",
    "3. Put files into the folder\n",
    "```\n",
    "    hadoop fs -put /input_files/lookandbook_hotel_list_20200203.csv /input_files/bedandBLD_master_list_20200203.csv /user/solution/task1/\n",
    "```\n",
    "4. In hive, \n",
    "```\n",
    "    hive> CREATE TABLE IF NOT EXISTS load_advertiser_hotels (\n",
    "            hotel_id string,\n",
    "            hotel_name string,)\n",
    "            ROW FORMAT DELIMITED\n",
    "            FIELDS TERMINATED BY ',';\n",
    "\n",
    "    hive> LOAD DATA INPATH '/input_files/bedandBLD_master_list_20200203.csv' INTO TABLE load_advertiser_hotels\n",
    "          LOAD DATA INPATH '/input_files/lookandbook_hotel_list_20200203.csv' INTO TABLE load_advertiser_hotels\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98846713",
   "metadata": {},
   "source": [
    "### Task2\n",
    " data quality check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "path = os.getcwd()+\"/input_files/\"\n",
    "\n",
    "ALLOWED_EXTENSTIONS = {\".csv\"}\n",
    "ALLOWED_DELIMITER =[',']\n",
    "\n",
    "def is_file_name_format_OK(filelist):\n",
    "    \"\"\"The file name format check\n",
    "\n",
    "    Args:\n",
    "      filelist: a file list in the directory\n",
    "\n",
    "    Returns:\n",
    "      True if the format is OK\n",
    "    \"\"\"\n",
    "\n",
    "    for filename in filelist:\n",
    "        extension = os.path.splitext(filename)[1]\n",
    "        if extension not in ALLOWED_EXTENSTIONS:\n",
    "          print(\"{} is not a valid file name format\".format(filename))\n",
    "          return False\n",
    "    return True\n",
    "            \n",
    "\n",
    "def is_file_empty(filelist):\n",
    "    \"\"\"The empty file check\n",
    "\n",
    "    Args:\n",
    "      filelist:a  file list in the directory\n",
    "\n",
    "    Returns:\n",
    "      True if the file empty \n",
    "    \"\"\"\n",
    "    for filename in filelist:\n",
    "      filepath = os.path.join(dirpath,filename)\n",
    "      if (os.path.exists(filepath) and os.stat(filepath).st_size == 0):\n",
    "        print(\"{} does not exist or is empty.\".format(filename))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def has_file_header(csvfile):\n",
    "  sampledata =csvfile.read(1024)\n",
    "  return csv.Sniffer().has_header(sampledata)\n",
    "\n",
    "def is_wrong_delimiter(csvfile):\n",
    "  is_wrong_delimiter = False\n",
    "  try:\n",
    "    dialect = csv.Sniffer().sniff(csvfile.readline(), ALLOWED_DELIMITER)\n",
    "  except:\n",
    "    is_wrong_delimiter = True\n",
    "  return is_wrong_delimiter\n",
    "\n",
    "def has_extra_comma(csvfile):\n",
    "  csvreader = csv.reader(csvfile, delimiter = \",\")\n",
    "  for linenum,fieldlist in enumerate(csvreader):\n",
    "    if '' in set(fieldlist):\n",
    "      print(\"Line.{} has the extra comma.\".format(linenum+1))\n",
    "      return True\n",
    "  return False\n",
    "\n",
    "\n",
    "def has_specialchar(csvfile):\n",
    "  csvreader = csv.reader(csvfile, delimiter = \",\")\n",
    "  for fieldlist in csvreader:\n",
    "    for field in fieldlist:\n",
    "        if re.compile('[^ 0-9a-zA-Z_-]+').search(field):\n",
    "          print(\"{} contains special character.\".format(field))\n",
    "          return True\n",
    "  return False\n",
    "\n",
    "\n",
    "def data_quality_check(path):\n",
    "\n",
    "  filenames = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "  # for the first two check, I check all the files because it saves time by not including \"with open\" operation\n",
    "  if not is_file_name_format_OK(filenames):\n",
    "    print(\"Check the file name!\")\n",
    "    return\n",
    "  \n",
    "  if is_file_empty(filenames):\n",
    "    print(\"Check the file empty!\")\n",
    "    return\n",
    "\n",
    "  for filename in filenames:\n",
    "    filepath = os.path.join(path,filename)\n",
    "    with open(filepath, 'r', encoding='UTF-8') as csvfile:\n",
    "      #check the header first\n",
    "      if not has_file_header(csvfile):\n",
    "        print(\"{} does not have header.\".format(filename))\n",
    "        return \n",
    "      else:\n",
    "        #check the delimiter\n",
    "        csvfile.seek(0)\n",
    "        if is_wrong_delimiter(csvfile):\n",
    "          print(\"{} is wrong delimiter.\".format(filename))\n",
    "          return\n",
    "        else:\n",
    "          #check extra comma\n",
    "          csvfile.seek(0)\n",
    "          if has_extra_comma(csvfile):\n",
    "            print(\"{} has extra comma.\".format(filename))\n",
    "            return\n",
    "          else:\n",
    "            #check special character\n",
    "            csvfile.seek(0)\n",
    "            if has_specialchar(csvfile):\n",
    "              print(\"{} has special character.\".format(filename))\n",
    "              return\n",
    "  print (\"data quality check OK.\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c55f78",
   "metadata": {},
   "source": [
    "#### deal with the analytics issues\n",
    "\n",
    "Create a fact table called hotel.\n",
    "A dimention table called hotel_info and a dimention table called time.\\\n",
    "In hotel table, the id is sequencial increament id which is primary key \n",
    "and make hotel_id and start_time as the foreign key for the hotel_info table and time table respecitively.\\\n",
    "In this case, hotel_id is unique and not null.\\\n",
    "When insert values into hotel_info table, make the hotel_name Distict to resolve duplicate issue.\\\n",
    "Extract the start_time value to create the respective fields in time table.\\\n",
    "Join the tables, can let analysts track the time for a hotel.\n",
    "\n",
    "Fact table:\n",
    "\n",
    "    hotel table\n",
    "    - id, Primary Key, Int\n",
    "    - hotel_id, Foreign Key, Int\n",
    "    - start_time, Foreign Key, Timestamp\n",
    "\n",
    "Dimention table:\n",
    "\n",
    "    hotel_info table\n",
    "    - hotel_id, Primary Key, Int\n",
    "    - hotel_name,Varchar\n",
    "    - active,Boolean\n",
    "    - removedbefore,Boolean\n",
    "\n",
    "    time table\n",
    "    - start_time,Primary Key, Timestamp\n",
    "    - hour\tInt\n",
    "    - day\tInt\n",
    "    - week\tInt\n",
    "    - month\tInt\n",
    "    - year\tInt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea3c9b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong Delimiter\n"
     ]
    }
   ],
   "source": [
    "with open(mypath, 'rb') as csvfile:\n",
    "    try:\n",
    "        dialect = csv.Sniffer().sniff(csvfile.readline(), [',',';'])\n",
    "        print(\"Delimiter is valid\")\n",
    "    except:\n",
    "        print(\"Wrong Delimiter\")\n",
    "\n",
    "\n",
    "#find header another way\n",
    "csvreader = csv.reader(csvfile, delimiter = \",\")\n",
    "header = next(csvreader)\n",
    "has_header = not any(field.isdigit() for field in header)\n",
    "\n",
    "import json\n",
    "status_dict = dict()\n",
    "status_dict[filename]= dict()\n",
    "status_dict[filename]['header'] = 'True'\n",
    "status_dict[filename]['header'] = 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3db4f62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delimiter is valid\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(path + '/input_files/lookandbook_hotel_list_20200203.csv', mode='r') as csv_file:\n",
    "    #check if it is valid delimiter\n",
    "        try:\n",
    "            dialect = csv.Sniffer().sniff(csv_file.readline(), [',',';'])\n",
    "            print(\"Delimiter is valid\")\n",
    "        except:\n",
    "            print(\"Wrong Delimiter\")\n",
    "\n",
    "for data in (data1, data2):\n",
    "    s=csv.Sniffer()\n",
    "    d = s.sniff(data)\n",
    "    print(repr(d.delimiter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9462be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #check if there is extra comma\n",
    "    keys = csv_file.readline().strip().split(',') # Read header line\n",
    "    for line in csv_file:\n",
    "        line = line.strip()\n",
    "        row = re.split(r'(?!\\s),(?!\\s)',line)\n",
    "        list.append(dict(zip(keys, row)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
